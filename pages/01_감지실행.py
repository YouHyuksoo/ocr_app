# ë¦¬íŒ©í† ë§ëœ Streamlit OCR ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ (ê°ì§€ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨ ì²˜ë¦¬ ê°œì„ )
import streamlit as st
import atexit
import torch
from datetime import datetime
from PIL import Image
import cv2
from collections import deque
import numpy as np
import base64
from io import BytesIO

# ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
from utils.config import load_config
from utils.logger import log_detection, log_plc_transmission
from components.status import StatusBar
from components.sidebar import setup_sidebar
from services.detector import setup_detector, process_detections
from services.plc import send_to_plc
from services.snapshot import save_snapshot
from utils.roi import draw_roi
from services.camera import connect_camera, release_camera

import debugpy

st.set_page_config(layout="wide", page_title="OCR ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“¸")
st.title("ğŸ“¸ ì°¨ëŸ‰ë²ˆí˜¸ ê²€ì¶œì‹œìŠ¤í…œ")
status_bar = StatusBar()

# if "debug_listening" not in st.session_state:
#     try:
#         debugpy.listen(5678)
#         st.session_state.debug_listening = True
#         st.write("ğŸ§© ë””ë²„ê±° ì—°ê²° ëŒ€ê¸° ì¤‘...")
#         debugpy.wait_for_client()
#         st.success("ğŸ ë””ë²„ê±°ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")
#     except RuntimeError:
#         st.warning("ë””ë²„ê±°ê°€ ì´ë¯¸ ì—°ê²°ë˜ì–´ ìˆê±°ë‚˜ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")


# ì•± ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜
def cleanup():
    if "camera" in st.session_state and st.session_state.camera is not None:
        st.session_state.camera.release()
        st.session_state.camera = None
        print("ì¹´ë©”ë¼ ë¦¬ì†ŒìŠ¤ê°€ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.")


atexit.register(cleanup)

# ìƒë‹¨ì—ì„œ ì„¤ì • ë¡œë“œ
ocr_config = load_config("ocr_system") or {}
roi_config = load_config("roi") or {}
camera_config = load_config("camera") or {}
detection_config = load_config("detection") or {
    "entry_direction": "left_to_right",
    "digit_count": 3,
    "model_path": "yolov8n.pt",
}

# ì„¤ì •ê°’ ì¶”ì¶œ
auto_start = ocr_config.get("auto_start_detection", False)
model_path = detection_config.get("model_path", "yolov8n.pt")
camera_width = camera_config.get("width", 320)
camera_height = camera_config.get("height", 240)
expected_digits = detection_config.get("digit_count", 3)
entry_direction = detection_config.get("entry_direction", "left_to_right")

# ë°©í–¥ ë§¤í•‘ ì •ì˜ (ìƒìˆ˜ë¡œ ë¶„ë¦¬)
DIRECTION_MAP = {
    "left_to_right": "ì¢Œâ†’ìš°",
    "right_to_left": "ìš°â†’ì¢Œ",
    "top_to_bottom": "ìƒâ†’í•˜",
    "bottom_to_top": "í•˜â†’ìƒ",
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
st.session_state.setdefault("detecting", auto_start)
st.session_state.setdefault("need_camera_connection", auto_start)
st.session_state.setdefault("auto_start_done", False)
st.session_state.setdefault("camera", None)
st.session_state.setdefault("start_button_clicked", False)

# setup_sidebar í•¨ìˆ˜ í˜¸ì¶œ
(
    video_source,
    confidence_threshold,
    is_digit_mode,
    plc_settings,
    sidebar_camera_index,
) = setup_sidebar(status_bar)

# ë¹„ë””ì˜¤ ì†ŒìŠ¤ ì„ íƒ í›„ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ í‘œì‹œ
if video_source == "ì›¹ìº ":
    st.sidebar.info(f"ğŸ“· í˜„ì¬ ì¹´ë©”ë¼ ì¸ë±ìŠ¤: {sidebar_camera_index}")

# ì´ë¯¸ì§€ ì—…ë¡œë“œ UI
uploaded_image = None
if video_source == "ì´ë¯¸ì§€":
    uploaded_image = st.sidebar.file_uploader(
        "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "png"], help="ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )

# detection_configì—ì„œ ì„¤ì •ê°’ ì¶”ì¶œ
model_settings = {
    "conf": detection_config.get("conf", 0.25),
    "iou": detection_config.get("iou", 0.45),
    "agnostic_nms": detection_config.get("agnostic_nms", False),
    "max_det": detection_config.get("max_det", 10),
}

# ëª¨ë¸ ì´ˆê¸°í™” ì‹œ ì„¤ì •ê°’ ì „ë‹¬
model = setup_detector(model_path, model_settings)
recent_logs = deque(maxlen=100)
last_sent_digit = None
sent_history = deque(maxlen=10)

# ë²„íŠ¼ ë° ì´ë¯¸ì§€ í™•ëŒ€/ì¶•ì†Œ ì»¨í…Œì´ë„ˆ (í•­ìƒ ìƒë‹¨ì— ìœ„ì¹˜í•˜ë„ë¡ ê³ ì •)
with st.container():
    start_col, stop_col, release_col, zoom_out_col, zoom_in_col = st.columns(5)
    start_button = start_col.button("â–¶ï¸ ê°ì§€ ì‹œì‘")
    stop_button = stop_col.button("â¹ï¸ ê°ì§€ ì¤‘ì§€")
    release_button = release_col.button("ğŸ”Œ ì¹´ë©”ë¼ ë„ê¸°")
    zoom_out = zoom_out_col.button("â– ì‘ê²Œ")
    zoom_in = zoom_in_col.button("â• í¬ê²Œ")

    if "image_width_percent" not in st.session_state:
        st.session_state.image_width_percent = 40

    if zoom_out and st.session_state.image_width_percent > 10:
        st.session_state.image_width_percent -= 10
    if zoom_in and st.session_state.image_width_percent < 100:
        st.session_state.image_width_percent += 10

if start_button:
    st.session_state.detecting = True
    st.session_state.start_button_clicked = True
    st.session_state.need_camera_connection = video_source == "ì›¹ìº "
    if video_source == "ì›¹ìº " and not isinstance(
        st.session_state.camera, cv2.VideoCapture
    ):
        cap, frame = connect_camera(
            sidebar_camera_index,  # camera_index ëŒ€ì‹  sidebar_camera_index ì‚¬ìš©
            camera_width,
            camera_height,
            status_bar,
        )
        if isinstance(cap, cv2.VideoCapture):
            st.session_state.camera = cap
            st.success(f"ì¹´ë©”ë¼(ì¸ë±ìŠ¤: {sidebar_camera_index}) ì—°ê²° ì„±ê³µ")
        else:
            st.error(f"ì¹´ë©”ë¼(ì¸ë±ìŠ¤: {sidebar_camera_index}) ì—°ê²° ì‹¤íŒ¨")
            st.session_state.detecting = False

if stop_button:
    st.session_state.detecting = False
    status_bar.update("ê°ì§€ ì¤‘ì§€ë¨")
    cv2.destroyAllWindows()

if release_button:
    if st.session_state.camera:
        release_camera(status_bar)
        st.session_state.camera = None
        st.success("ì¹´ë©”ë¼ ì—°ê²° í•´ì œ ì™„ë£Œ")
    else:
        st.warning("ì—°ê²°ëœ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ê°ì§€ ì²˜ë¦¬ ë¡œì§
with st.container():
    FRAME_WINDOW = st.empty()
    LOG_WINDOW = st.empty()

    if st.session_state.detecting:
        if video_source == "ì´ë¯¸ì§€":
            if uploaded_image:
                file_bytes = np.asarray(
                    bytearray(uploaded_image.read()), dtype=np.uint8
                )
                frame = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

                try:
                    status_bar.update("ì´ë¯¸ì§€ì—ì„œ ê°ì²´ ê°ì§€ ì¤‘...")
                    detections, detected_digits, combined, annotated_display = (
                        process_detections(
                            model,
                            frame,
                            confidence_threshold,
                            is_digit_mode,
                            detection_config,
                            status_bar,
                        )
                    )

                    # ê°ì§€ëœ ìˆ«ì í‘œì‹œ
                    if is_digit_mode:
                        st.sidebar.markdown("### ê°ì§€ ê²°ê³¼")
                        st.sidebar.markdown(
                            f"- **ì§„ì… ë°©í–¥**: {DIRECTION_MAP.get(entry_direction)}"
                        )
                        st.sidebar.markdown(f"- **ì˜ˆìƒ ìë¦¿ìˆ˜**: {expected_digits}")
                        st.sidebar.markdown(f"- **ê°ì§€ëœ ìˆ«ì**: `{combined}`")

                        if len(detected_digits) != expected_digits:
                            st.sidebar.warning(
                                f"âš ï¸ ì˜ˆìƒ ìë¦¿ìˆ˜({expected_digits})ì™€ ë‹¤ë¥¸ {len(detected_digits)}ìë¦¬ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"
                            )

                    buffered = BytesIO()
                    Image.fromarray(
                        cv2.cvtColor(annotated_display, cv2.COLOR_BGR2RGB)
                    ).save(buffered, format="PNG")
                    img_base64 = base64.b64encode(buffered.getvalue()).decode()

                    FRAME_WINDOW.markdown(
                        f"<img src='data:image/png;base64,{img_base64}' style='width:{st.session_state.image_width_percent}%;'/>",
                        unsafe_allow_html=True,
                    )

                except Exception as e:
                    st.error(f"ì´ë¯¸ì§€ ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    status_bar.update("ì˜¤ë¥˜ ë°œìƒ. ê°ì§€ ì¤‘ë‹¨.")

        elif video_source == "ì›¹ìº ":
            if st.session_state.camera:
                while st.session_state.detecting:
                    ret, frame = st.session_state.camera.read()
                    if not ret:
                        st.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                        break

                    try:
                        status_bar.update("ì›¹ìº ì—ì„œ ê°ì²´ ê°ì§€ ì¤‘...")
                        detections, detected_digits, combined, annotated_display = (
                            process_detections(
                                model,
                                frame,
                                confidence_threshold,
                                is_digit_mode,
                                detection_config,
                                status_bar,
                            )
                        )

                        # ê°ì§€ëœ ìˆ«ì í‘œì‹œ
                        if is_digit_mode:
                            st.sidebar.markdown("### ê°ì§€ ê²°ê³¼")
                            st.sidebar.markdown(
                                f"- **ì§„ì… ë°©í–¥**: {DIRECTION_MAP.get(entry_direction)}"
                            )
                            st.sidebar.markdown(f"- **ì˜ˆìƒ ìë¦¿ìˆ˜**: {expected_digits}")
                            st.sidebar.markdown(f"- **ê°ì§€ëœ ìˆ«ì**: `{combined}`")

                            if len(detected_digits) != expected_digits:
                                st.sidebar.warning(
                                    f"âš ï¸ ì˜ˆìƒ ìë¦¿ìˆ˜({expected_digits})ì™€ ë‹¤ë¥¸ {len(detected_digits)}ìë¦¬ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"
                                )

                        buffered = BytesIO()
                        Image.fromarray(
                            cv2.cvtColor(annotated_display, cv2.COLOR_BGR2RGB)
                        ).save(buffered, format="PNG")
                        img_base64 = base64.b64encode(buffered.getvalue()).decode()

                        FRAME_WINDOW.markdown(
                            f"<img src='data:image/png;base64,{img_base64}' style='width:{st.session_state.image_width_percent}%;'/>",
                            unsafe_allow_html=True,
                        )

                    except Exception as e:
                        st.error(f"ì›¹ìº  ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        status_bar.update("ì˜¤ë¥˜ ë°œìƒ. ê°ì§€ ì¤‘ë‹¨.")
                        break
            else:
                st.error(
                    "ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê°ì§€ ì‹œì‘ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”."
                )
                st.session_state.detecting = False

st.markdown("---")
st.markdown("### ì¹´ë©”ë¼ ì„¤ì •ê°’")
st.write(f"- **ì¹´ë©”ë¼ í•´ìƒë„**: {camera_width} x {camera_height}")
st.write(f"- **ëª¨ë¸ ê²½ë¡œ**: {model_path}")

if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        device = torch.device(f"cuda:{i}")
        torch.cuda.set_per_process_memory_fraction(0.7, device)

if not st.session_state.detecting and st.session_state.camera:
    release_camera(status_bar)
    st.session_state.camera = None
