# pages/02_ëª¨ë¸_í•™ìŠµ.py
# í•™ìŠµ íŒŒë¼ë¯¸í„° ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ê¸°ëŠ¥ì´ ì¶”ê°€ëœ YOLO ëª¨ë¸ í•™ìŠµ í˜ì´ì§€

import streamlit as st
import zipfile
import os
from datetime import datetime
from utils.training import run_training
from utils.logger import log_training
from utils.config import load_config, save_config
import matplotlib.pyplot as plt
import pandas as pd
import glob
from PIL import Image

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="YOLO ëª¨ë¸ í•™ìŠµ", page_icon="ğŸ§ ", layout="wide")

# í˜ì´ì§€ í—¤ë” ì„¤ì •
st.title("ğŸ§  YOLO ëª¨ë¸ í•™ìŠµ")

# í˜„ì¬ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
training_config = load_config("training")  # í•™ìŠµ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°

# í•™ìŠµ ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
if not training_config:
    training_config = {
        "model_arch": "yolov8n.pt",
        "epochs": 100,
        "batch": 16,
        "imgsz": 640,
        "optimizer": "Adam",
        "learning_rate": 0.001,
        "project_name": "ocr_digit",
    }

# í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
with st.expander("í˜„ì¬ ëª¨ë¸ ì„¤ì • ì •ë³´", expanded=False):
    st.info(
        f"""
        **í˜„ì¬ ëª¨ë¸ ì„¤ì •:**
        - ëª¨ë¸ ê²½ë¡œ: {training_config.get('model_path', 'yolov8n.pt')}
        """
    )

# ë°ì´í„°ì…‹ ì—…ë¡œë“œ ì„¹ì…˜
with st.expander("ğŸ“¦ í•™ìŠµìš© ë°ì´í„°ì…‹ ì—…ë¡œë“œ", expanded=True):
    uploaded_file = st.file_uploader("ğŸ”¼ ZIP í˜•ì‹ì˜ í•™ìŠµ ë°ì´í„°ì…‹ ì—…ë¡œë“œ", type=["zip"])
    if uploaded_file:
        dataset_dir = "dataset"
        # ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚­ì œ
        if os.path.exists(dataset_dir):
            import shutil

            shutil.rmtree(dataset_dir)
        os.makedirs(dataset_dir, exist_ok=True)

        # ì••ì¶• í•´ì œ
        with zipfile.ZipFile(uploaded_file, "r") as zip_ref:
            zip_ref.extractall(dataset_dir)

        # ì¤‘ì²©ëœ dataset í´ë”ê°€ ìˆëŠ” ê²½ìš° ìë™ ì´ë™ ì²˜ë¦¬
        inner_dataset = os.path.join(dataset_dir, "dataset")
        if os.path.exists(inner_dataset):
            for item in os.listdir(inner_dataset):
                src = os.path.join(inner_dataset, item)
                dst = os.path.join(dataset_dir, item)
                shutil.move(src, dst)
            shutil.rmtree(inner_dataset)

        # data.yamlì„ ìµœìƒìœ„ë¡œ ë³µì‚¬
        for root, dirs, files in os.walk(dataset_dir):
            for f in files:
                if f == "data.yaml":
                    src_path = os.path.join(root, f)
                    dst_path = os.path.join(dataset_dir, "data.yaml")
                    if src_path != dst_path:
                        import shutil

                        shutil.copy(src_path, dst_path)
                    break

        st.session_state.uploaded_filename = uploaded_file.name
        st.success("âœ… ì••ì¶• í•´ì œ ì™„ë£Œ")

        # ğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            image_files = glob.glob(
                os.path.join(dataset_dir, "images", "*.jpg")
            ) + glob.glob(os.path.join(dataset_dir, "images", "*.png"))

            if image_files:
                for i, img_path in enumerate(image_files[:3]):
                    img = Image.open(img_path)
                    st.image(img, caption=os.path.basename(img_path), width=300)
            else:
                st.info("ë¯¸ë¦¬ë³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. (images/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”)")

        # ğŸ“‚ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ë³´ê¸°
        st.subheader("ğŸ“‚ ì••ì¶• í•´ì œëœ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ë³´ê¸°")
        with st.expander("ğŸ“‚ ë””ë ‰í† ë¦¬ ë³´ê¸° (í´ë¦­í•´ì„œ í¼ì¹˜ê¸°)", expanded=False):
            for root, dirs, files in os.walk(dataset_dir):
                indent = "&nbsp;&nbsp;&nbsp;&nbsp;" * (
                    root.count(os.sep) - dataset_dir.count(os.sep)
                )
                st.markdown(
                    f"{indent}ğŸ“‚ `{os.path.relpath(root, dataset_dir)}`",
                    unsafe_allow_html=True,
                )
                for f in files:
                    st.markdown(
                        f"{indent}&nbsp;&nbsp;&nbsp;&nbsp;ğŸ“„ `{f}`",
                        unsafe_allow_html=True,
                    )

# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • í¼
st.subheader("ğŸ’¾ í•™ìŠµ ì„¤ì •")
col1, col2 = st.columns([3, 1])

with col1:
    model_arch = st.selectbox(
        "YOLO ëª¨ë¸",
        ["yolov8n.pt", "yolov8s.pt", "yolov8m.pt", "yolov8l.pt", "yolov8x.pt"],
        index=(
            [
                "yolov8n.pt",
                "yolov8s.pt",
                "yolov8m.pt",
                "yolov8l.pt",
                "yolov8x.pt",
            ].index(training_config.get("model_arch", "yolov8n.pt"))
            if training_config.get("model_arch")
            in ["yolov8n.pt", "yolov8s.pt", "yolov8m.pt", "yolov8l.pt", "yolov8x.pt"]
            else 0
        ),
        help="YOLO ëª¨ë¸ì˜ í¬ê¸°ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n\n"
        "ğŸ“Š ëª¨ë¸ í¬ê¸° ë¹„êµ:\n"
        "- yolov8n.pt: ê°€ì¥ ì‘ê³  ë¹ ë¥¸ ëª¨ë¸ (ì¶”ë¡  ì†ë„ âš¡ï¸âš¡ï¸âš¡ï¸, ì •í™•ë„ â˜…â˜†â˜†)\n"
        "- yolov8s.pt: ì‘ì€ í¬ê¸° ëª¨ë¸ (ì¶”ë¡  ì†ë„ âš¡ï¸âš¡ï¸, ì •í™•ë„ â˜…â˜…â˜†)\n"
        "- yolov8m.pt: ì¤‘ê°„ í¬ê¸° ëª¨ë¸ (ì¶”ë¡  ì†ë„ âš¡ï¸, ì •í™•ë„ â˜…â˜…â˜…)\n"
        "- yolov8l.pt: í° í¬ê¸° ëª¨ë¸ (ì¶”ë¡  ì†ë„ ğŸ¢, ì •í™•ë„ â˜…â˜…â˜…â˜…)\n"
        "- yolov8x.pt: ê°€ì¥ í° ëª¨ë¸ (ì¶”ë¡  ì†ë„ ğŸ¢ğŸ¢, ì •í™•ë„ â˜…â˜…â˜…â˜…â˜…)\n\n"
        "ğŸ’¡ ê¶Œì¥: ìˆ«ì ì¸ì‹ìš©ìœ¼ë¡œëŠ” yolov8n.ptë‚˜ yolov8s.ptë¡œ ì‹œì‘í•´ë³´ì„¸ìš”.",
    )

epochs = st.slider(
    "Epoch ìˆ˜",
    1,
    300,
    value=int(training_config.get("epochs", 100)),
    help="ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí•´ì„œ í•™ìŠµí• ì§€ ì„¤ì •í•©ë‹ˆë‹¤.\n\n"
    "ğŸ“ epoch ì„¤ì • ê°€ì´ë“œ:\n"
    "- ë„ˆë¬´ ì ìœ¼ë©´ (< 50): í•™ìŠµì´ ì¶©ë¶„íˆ ì´ë£¨ì–´ì§€ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\n"
    "- ë„ˆë¬´ ë§ìœ¼ë©´ (> 200): ê³¼ì í•©ì´ ë°œìƒí•  ìˆ˜ ìˆìŒ\n"
    "- Early Stopping: ì„±ëŠ¥ ê°œì„ ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ í•™ìŠµ ì¤‘ë‹¨\n\n"
    "ğŸ’¡ ê¶Œì¥ê°’: 100~150 ì •ë„ì—ì„œ ì‹œì‘í•˜ì—¬ ì¡°ì •",
)

batch = st.slider(
    "Batch Size",
    1,
    64,
    value=int(training_config.get("batch", 16)),
    help="í•œ ë²ˆì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê°œìˆ˜ì…ë‹ˆë‹¤.\n\n"
    "ğŸ” batch size íŠ¹ì§•:\n"
    "- í° ê°’: í•™ìŠµì´ ì•ˆì •ì ì´ì§€ë§Œ ë” ë§ì€ ë©”ëª¨ë¦¬ í•„ìš”\n"
    "- ì‘ì€ ê°’: ì ì€ ë©”ëª¨ë¦¬ë¡œ ê°€ëŠ¥í•˜ë‚˜ í•™ìŠµì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ\n"
    "- GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ í•„ìš”\n\n"
    "ğŸ’¡ ê¶Œì¥ê°’: 16~32 (GPU ë©”ëª¨ë¦¬ ì—¬ìœ ê°€ ìˆëŠ” ê²½ìš°)",
)

imgsz = st.selectbox(
    "ì´ë¯¸ì§€ í¬ê¸°",
    [416, 512, 640],
    index=(
        [416, 512, 640].index(training_config.get("imgsz", 640))
        if training_config.get("imgsz") in [416, 512, 640]
        else 2
    ),
    help="í•™ìŠµì— ì‚¬ìš©í•  ì´ë¯¸ì§€ í¬ê¸°(í”½ì…€)ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n\n"
    "ğŸ–¼ï¸ í¬ê¸°ë³„ íŠ¹ì§•:\n"
    "- 416: ì‘ì€ í¬ê¸°, ë¹ ë¥¸ í•™ìŠµ/ì¶”ë¡ , ì‘ì€ ê°ì²´ ê°ì§€ë ¥ ë‚®ìŒ\n"
    "- 512: ì¤‘ê°„ í¬ê¸°, ê· í˜•ì¡íŒ ì„±ëŠ¥\n"
    "- 640: í° í¬ê¸°, ëŠë¦° í•™ìŠµ/ì¶”ë¡ , ì‘ì€ ê°ì²´ ê°ì§€ë ¥ ë†’ìŒ\n\n"
    "ğŸ’¡ ê¶Œì¥: ìˆ«ì ê°ì§€ì˜ ê²½ìš° 512ë‚˜ 640 ê¶Œì¥",
)

optimizer = st.selectbox(
    "Optimizer",
    ["SGD", "Adam"],
    index=(
        ["SGD", "Adam"].index(training_config.get("optimizer", "Adam"))
        if training_config.get("optimizer") in ["SGD", "Adam"]
        else 1
    ),
    help="í•™ìŠµì— ì‚¬ìš©í•  ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•©ë‹ˆë‹¤.\n\n"
    "ğŸ”„ ì˜µí‹°ë§ˆì´ì € ë¹„êµ:\n"
    "- SGD (Stochastic Gradient Descent):\n"
    "  â€¢ ì•ˆì •ì ì´ì§€ë§Œ ìˆ˜ë ´ì´ ëŠë¦¼\n"
    "  â€¢ í•™ìŠµë¥  ì„¤ì •ì´ ì¤‘ìš”\n"
    "  â€¢ ì§€ì—­ ìµœì í•´ì— ë¹ ì§ˆ ìˆ˜ ìˆìŒ\n\n"
    "- Adam (Adaptive Moment Estimation):\n"
    "  â€¢ ìë™ìœ¼ë¡œ í•™ìŠµë¥  ì¡°ì ˆ\n"
    "  â€¢ ë¹ ë¥¸ ìˆ˜ë ´\n"
    "  â€¢ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì¢‹ì€ ì„±ëŠ¥\n\n"
    "ğŸ’¡ ê¶Œì¥: ì¼ë°˜ì ìœ¼ë¡œ Adam ì‚¬ìš© ê¶Œì¥",
)

learning_rate = st.number_input(
    "Learning Rate",
    value=float(training_config.get("learning_rate", 0.001)),
    format="%f",
    min_value=0.0001,
    max_value=0.1,
    step=0.0001,
    help="ëª¨ë¸ì˜ í•™ìŠµ ì†ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•™ìŠµë¥ ì…ë‹ˆë‹¤.\n\n"
    "ğŸ“ˆ í•™ìŠµë¥  ì„¤ì • ê°€ì´ë“œ:\n"
    "- ë„ˆë¬´ í¬ë©´ (> 0.01):\n"
    "  â€¢ í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§ˆ ìˆ˜ ìˆìŒ\n"
    "  â€¢ ìµœì ì ì„ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŒ\n\n"
    "- ë„ˆë¬´ ì‘ìœ¼ë©´ (< 0.0001):\n"
    "  â€¢ í•™ìŠµì´ ë§¤ìš° ëŠë¦¼\n"
    "  â€¢ ì§€ì—­ ìµœì í•´ì— ê°‡í ìˆ˜ ìˆìŒ\n\n"
    "ğŸ’¡ ê¶Œì¥ê°’:\n"
    "- Adam: 0.001 (ê¸°ë³¸ê°’)\n"
    "- SGD: 0.01",
)

project_name = st.text_input(
    "í”„ë¡œì íŠ¸ ì´ë¦„",
    value=training_config.get("project_name", "ocr_digit"),
    help="í•™ìŠµ ê²°ê³¼ê°€ ì €ì¥ë  í”„ë¡œì íŠ¸ í´ë”ì˜ ì´ë¦„ì…ë‹ˆë‹¤.\n\n"
    "ğŸ“ ì €ì¥ ìœ„ì¹˜:\n"
    "- runs/detect/{í”„ë¡œì íŠ¸ëª…}/\n"
    "- ê°™ì€ ì´ë¦„ìœ¼ë¡œ ì¬ì‹¤í–‰ ì‹œ ê¸°ì¡´ ê²°ê³¼ë¥¼ ë®ì–´ì”ë‹ˆë‹¤.\n\n"
    "ğŸ’¡ íŒ: ì‹¤í—˜ë³„ë¡œ ë‹¤ë¥¸ ì´ë¦„ì„ ì‚¬ìš©í•˜ë©´ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.",
)

# ì„¤ì • ì €ì¥ ì„¹ì…˜
st.divider()
st.subheader("âš™ï¸ ì„¤ì • ì €ì¥")
save_col1, save_col2, save_col3 = st.columns([2, 1, 1])

with save_col1:
    save_as_preset = st.text_input("ì„¤ì • ì €ì¥ ì´ë¦„", placeholder="ìƒˆ ì„¤ì • ì´ë¦„ ì…ë ¥...")

with save_col2:
    if st.button(
        "ì„¤ì •ë§Œ ì €ì¥",
        help="í•™ìŠµì„ ì‹œì‘í•˜ì§€ ì•Šê³  í˜„ì¬ ì„¤ì •ë§Œ ì €ì¥í•©ë‹ˆë‹¤",
        use_container_width=True,
    ):
        current_training = {
            "model_arch": model_arch,
            "epochs": epochs,
            "batch": batch,
            "imgsz": imgsz,
            "optimizer": optimizer,
            "learning_rate": learning_rate,
            "project_name": project_name,
        }
        save_config("training", current_training)
        st.success("âœ… í•™ìŠµ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í•™ìŠµ ì‹¤í–‰ ì„¹ì…˜
st.divider()
st.subheader("ğŸ“ˆ ë§ˆì§€ë§‰ í•™ìŠµ ê²°ê³¼ ì¡°íšŒ")
if st.button("ğŸ“‚ ë§ˆì§€ë§‰ í•™ìŠµ ê²°ê³¼ ë³´ê¸°"):
    st.subheader("ğŸ“Š í•™ìŠµ ê²°ê³¼ ìš”ì•½")
    result_dir = os.path.join(
        "runs", "detect", training_config.get("project_name", "ocr_digit")
    )
    csv_path = os.path.join(result_dir, "results.csv")
    if os.path.exists(csv_path):
        df = pd.read_csv(csv_path)
        st.line_chart(
            df[["metrics/precision(B)", "metrics/recall(B)", "metrics/mAP50(B)"]]
        )
        best_model_path = os.path.join(result_dir, "weights", "best.pt")
        if os.path.exists(best_model_path):
            with open(best_model_path, "rb") as f:
                st.download_button("ğŸ“¥ Best ëª¨ë¸ ë‹¤ìš´ë¡œë“œ", f, file_name="best.pt")
    else:
        st.warning("ì´ì „ì— ì €ì¥ëœ í•™ìŠµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.subheader("ğŸ–¼ï¸ ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”")
    image_files = [
        "F1_curve.png",
        "P_curve.png",
        "R_curve.png",
        "PR_curve.png",
        "confusion_matrix.png",
        "confusion_matrix_normalized.png",
        "labels.jpg",
        "labels_correlogram.jpg",
        "val_batch0_pred.jpg",
        "val_batch1_pred.jpg",
        "val_batch0_labels.jpg",
        "val_batch1_labels.jpg",
    ]
    images = []
    for file in image_files:
        img_path = os.path.join(result_dir, file)
        if os.path.exists(img_path):
            images.append((file, img_path))

    if images:
        cols = st.columns(4)
        for i, (name, path) in enumerate(images):
            with open(path, "rb") as f:
                img = f.read()
            cols[i % 4].image(img, caption=name, use_container_width=True)
    else:
        st.info(
            "ğŸ“ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. runs/detect/{project_name}/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )


if st.button("ğŸš€ í•™ìŠµ ì‹œì‘"):
    current_training = {
        "model_arch": model_arch,
        "epochs": epochs,
        "batch": batch,
        "imgsz": imgsz,
        "optimizer": optimizer,
        "learning_rate": learning_rate,
        "project_name": project_name,
    }
    save_config("training", current_training)

    start_time = datetime.now()

    # data.yamlì˜ ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³´ì •
    import yaml

    yaml_path = os.path.abspath("dataset/data.yaml")
    if os.path.exists(yaml_path):
        with open(yaml_path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        for key in ["train", "val"]:
            if key in data:
                data[key] = os.path.abspath(data[key]).replace("\\", "/")
        with open(yaml_path, "w", encoding="utf-8") as f:
            yaml.dump(data, f, allow_unicode=True)

    data_yaml = yaml_path
    yolo_cmd = (
        f"yolo task=detect mode=train model={model_arch} data={data_yaml} "
        f"epochs={epochs} batch={batch} imgsz={imgsz} lr0={learning_rate} "
        f"optimizer={optimizer.lower()} name={project_name}"
    )
    st.info(f"ğŸ“¡ í•™ìŠµ ëª…ë ¹ ì‹¤í–‰ ì¤‘: {yolo_cmd}")

    with st.spinner("YOLO í•™ìŠµ ì§„í–‰ ì¤‘..."):
        result = run_training(yolo_cmd)

    end_time = datetime.now()

    if result.returncode == 0:
        st.success("ğŸ‰ í•™ìŠµ ì„±ê³µ")
        log_training(start_time, end_time, current_training, "success")

        # ìµœì¢… ëª¨ë¸ ê²½ë¡œë¥¼ config.yamlì— ì €ì¥
        best_model_path = os.path.join(result_dir, "weights", "best.pt")
        if os.path.exists(best_model_path):
            save_config("detection", {"model_path": best_model_path})
            st.info(
                f"âœ… ìµœì¢… ëª¨ë¸ ê²½ë¡œê°€ config.yamlì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {best_model_path}"
            )

        # âœ… í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì¶”ê°€
        st.subheader("ğŸ–¼ï¸ ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”")
        image_files = [
            "F1_curve.png",
            "P_curve.png",
            "R_curve.png",
            "PR_curve.png",
            "confusion_matrix.png",
            "confusion_matrix_normalized.png",
            "labels.jpg",
            "labels_correlogram.jpg",
            "val_batch0_pred.jpg",
            "val_batch1_pred.jpg",
            "val_batch0_labels.jpg",
            "val_batch1_labels.jpg",
        ]
        images = []
        for file in image_files:
            img_path = os.path.join(result_dir, file)
            if os.path.exists(img_path):
                images.append((file, img_path))

        if images:
            cols = st.columns(4)
            for i, (name, path) in enumerate(images):
                with open(path, "rb") as f:
                    img = f.read()
                cols[i % 4].image(img, caption=name, use_column_width=True)
        else:
            st.info(
                "ğŸ“ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. runs/detect/{project_name}/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”."
            )
        st.subheader("ğŸ“Š í•™ìŠµ ê²°ê³¼ ìš”ì•½")
        result_dir = os.path.join("runs", "detect", project_name)
        csv_path = os.path.join(result_dir, "results.csv")
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            st.line_chart(
                df[["metrics/precision(B)", "metrics/recall(B)", "metrics/mAP50(B)"]]
            )
        else:
            st.warning("results.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if os.path.exists(best_model_path):
            with open(best_model_path, "rb") as f:
                st.download_button("ğŸ“¥ Best ëª¨ë¸ ë‹¤ìš´ë¡œë“œ", f, file_name="best.pt")
    else:
        st.error("âŒ í•™ìŠµ ì‹¤íŒ¨")
        st.code(result.stdout)
