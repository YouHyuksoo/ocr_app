# pages/02_ëª¨ë¸_í•™ìŠµ.py
# í•™ìŠµ íŒŒë¼ë¯¸í„° ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ê¸°ëŠ¥ì´ ì¶”ê°€ëœ YOLO ëª¨ë¸ í•™ìŠµ í˜ì´ì§€

import streamlit as st
import zipfile
import os
from datetime import datetime
from utils.training import run_training
from utils.logger import log_training
from utils.config import load_config, save_config
import matplotlib.pyplot as plt
import pandas as pd
import glob
from PIL import Image

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="YOLO ëª¨ë¸ í•™ìŠµ", page_icon="ğŸ§ ", layout="wide")

# í˜ì´ì§€ í—¤ë” ì„¤ì •
st.title("ğŸ§  YOLO ëª¨ë¸ í•™ìŠµ")

# í˜„ì¬ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
training_config = load_config("training")  # í•™ìŠµ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°

# í•™ìŠµ ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
if not training_config:
    training_config = {
        "model_arch": "yolov8n.pt",
        "epochs": 100,
        "batch": 16,
        "imgsz": 640,
        "optimizer": "Adam",
        "learning_rate": 0.001,
        "project_name": "ocr_digit",
    }

# í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
with st.expander("í˜„ì¬ ëª¨ë¸ ì„¤ì • ì •ë³´", expanded=False):
    st.info(
        f"""
        **í˜„ì¬ ëª¨ë¸ ì„¤ì •:**
        - ëª¨ë¸ ê²½ë¡œ: {training_config.get('model_path', 'yolov8n.pt')}
        """
    )

# ë°ì´í„°ì…‹ ì—…ë¡œë“œ ì„¹ì…˜
with st.expander("ğŸ“¦ í•™ìŠµìš© ë°ì´í„°ì…‹ ì—…ë¡œë“œ", expanded=True):
    uploaded_file = st.file_uploader("ğŸ”¼ ZIP í˜•ì‹ì˜ í•™ìŠµ ë°ì´í„°ì…‹ ì—…ë¡œë“œ", type=["zip"])
    if uploaded_file:
        dataset_dir = "dataset"
        # ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚­ì œ
        if os.path.exists(dataset_dir):
            import shutil

            shutil.rmtree(dataset_dir)
        os.makedirs(dataset_dir, exist_ok=True)

        # ì••ì¶• í•´ì œ
        with zipfile.ZipFile(uploaded_file, "r") as zip_ref:
            zip_ref.extractall(dataset_dir)

        # ì¤‘ì²©ëœ dataset í´ë”ê°€ ìˆëŠ” ê²½ìš° ìë™ ì´ë™ ì²˜ë¦¬
        inner_dataset = os.path.join(dataset_dir, "dataset")
        if os.path.exists(inner_dataset):
            for item in os.listdir(inner_dataset):
                src = os.path.join(inner_dataset, item)
                dst = os.path.join(dataset_dir, item)
                shutil.move(src, dst)
            shutil.rmtree(inner_dataset)

        # data.yamlì„ ìµœìƒìœ„ë¡œ ë³µì‚¬
        for root, dirs, files in os.walk(dataset_dir):
            for f in files:
                if f == "data.yaml":
                    src_path = os.path.join(root, f)
                    dst_path = os.path.join(dataset_dir, "data.yaml")
                    if src_path != dst_path:
                        import shutil

                        shutil.copy(src_path, dst_path)
                    break

        st.session_state.uploaded_filename = uploaded_file.name
        st.success("âœ… ì••ì¶• í•´ì œ ì™„ë£Œ")

        # ğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ–¼ï¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            image_files = glob.glob(
                os.path.join(dataset_dir, "images", "*.jpg")
            ) + glob.glob(os.path.join(dataset_dir, "images", "*.png"))

            if image_files:
                for i, img_path in enumerate(image_files[:3]):
                    img = Image.open(img_path)
                    st.image(img, caption=os.path.basename(img_path), width=300)
            else:
                st.info("ë¯¸ë¦¬ë³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. (images/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”)")

        # ğŸ“‚ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ë³´ê¸°
        st.subheader("ğŸ“‚ ì••ì¶• í•´ì œëœ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ë³´ê¸°")
        with st.expander("ğŸ“‚ ë””ë ‰í† ë¦¬ ë³´ê¸° (í´ë¦­í•´ì„œ í¼ì¹˜ê¸°)", expanded=False):
            for root, dirs, files in os.walk(dataset_dir):
                indent = "&nbsp;&nbsp;&nbsp;&nbsp;" * (
                    root.count(os.sep) - dataset_dir.count(os.sep)
                )
                st.markdown(
                    f"{indent}ğŸ“‚ `{os.path.relpath(root, dataset_dir)}`",
                    unsafe_allow_html=True,
                )
                for f in files:
                    st.markdown(
                        f"{indent}&nbsp;&nbsp;&nbsp;&nbsp;ğŸ“„ `{f}`",
                        unsafe_allow_html=True,
                    )

# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • í¼
st.subheader("ğŸ’¾ í•™ìŠµ ì„¤ì •")
col1, col2 = st.columns([3, 1])

with col1:
    model_arch = st.selectbox(
        "YOLO ëª¨ë¸",
        ["yolov8n.pt", "yolov8s.pt", "yolov8m.pt", "yolov8l.pt", "yolov8x.pt"],
        index=(
            [
                "yolov8n.pt",
                "yolov8s.pt",
                "yolov8m.pt",
                "yolov8l.pt",
                "yolov8x.pt",
            ].index(training_config.get("model_arch", "yolov8n.pt"))
            if training_config.get("model_arch")
            in ["yolov8n.pt", "yolov8s.pt", "yolov8m.pt", "yolov8l.pt", "yolov8x.pt"]
            else 0
        ),
    )

epochs = st.slider("Epoch ìˆ˜", 1, 300, value=int(training_config.get("epochs", 100)))

batch = st.slider("Batch Size", 1, 64, value=int(training_config.get("batch", 16)))

imgsz = st.selectbox(
    "ì´ë¯¸ì§€ í¬ê¸°",
    [416, 512, 640],
    index=(
        [416, 512, 640].index(training_config.get("imgsz", 640))
        if training_config.get("imgsz") in [416, 512, 640]
        else 2
    ),
)

optimizer = st.selectbox(
    "Optimizer",
    ["SGD", "Adam"],
    index=(
        ["SGD", "Adam"].index(training_config.get("optimizer", "Adam"))
        if training_config.get("optimizer") in ["SGD", "Adam"]
        else 1
    ),
)

learning_rate = st.number_input(
    "Learning Rate",
    value=float(training_config.get("learning_rate", 0.001)),
    format="%f",
    min_value=0.0001,
    max_value=0.1,
    step=0.0001,
)

project_name = st.text_input(
    "í”„ë¡œì íŠ¸ ì´ë¦„", value=training_config.get("project_name", "ocr_digit")
)

# ì„¤ì • ì €ì¥ ì„¹ì…˜
st.divider()
st.subheader("âš™ï¸ ì„¤ì • ì €ì¥")
save_col1, save_col2, save_col3 = st.columns([2, 1, 1])

with save_col1:
    save_as_preset = st.text_input("ì„¤ì • ì €ì¥ ì´ë¦„", placeholder="ìƒˆ ì„¤ì • ì´ë¦„ ì…ë ¥...")

with save_col2:
    if st.button(
        "ì„¤ì •ë§Œ ì €ì¥",
        help="í•™ìŠµì„ ì‹œì‘í•˜ì§€ ì•Šê³  í˜„ì¬ ì„¤ì •ë§Œ ì €ì¥í•©ë‹ˆë‹¤",
        use_container_width=True,
    ):
        current_training = {
            "model_arch": model_arch,
            "epochs": epochs,
            "batch": batch,
            "imgsz": imgsz,
            "optimizer": optimizer,
            "learning_rate": learning_rate,
            "project_name": project_name,
        }
        save_config("training", current_training)
        st.success("âœ… í•™ìŠµ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í•™ìŠµ ì‹¤í–‰ ì„¹ì…˜
st.divider()
st.subheader("ğŸ“ˆ ë§ˆì§€ë§‰ í•™ìŠµ ê²°ê³¼ ì¡°íšŒ")
if st.button("ğŸ“‚ ë§ˆì§€ë§‰ í•™ìŠµ ê²°ê³¼ ë³´ê¸°"):
    st.subheader("ğŸ“Š í•™ìŠµ ê²°ê³¼ ìš”ì•½")
    result_dir = os.path.join(
        "runs", "detect", training_config.get("project_name", "ocr_digit")
    )
    csv_path = os.path.join(result_dir, "results.csv")
    if os.path.exists(csv_path):
        df = pd.read_csv(csv_path)
        st.line_chart(
            df[["metrics/precision(B)", "metrics/recall(B)", "metrics/mAP50(B)"]]
        )
        best_model_path = os.path.join(result_dir, "weights", "best.pt")
        if os.path.exists(best_model_path):
            with open(best_model_path, "rb") as f:
                st.download_button("ğŸ“¥ Best ëª¨ë¸ ë‹¤ìš´ë¡œë“œ", f, file_name="best.pt")
    else:
        st.warning("ì´ì „ì— ì €ì¥ëœ í•™ìŠµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.subheader("ğŸ–¼ï¸ ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”")
    image_files = [
        "F1_curve.png",
        "P_curve.png",
        "R_curve.png",
        "PR_curve.png",
        "confusion_matrix.png",
        "confusion_matrix_normalized.png",
        "labels.jpg",
        "labels_correlogram.jpg",
        "val_batch0_pred.jpg",
        "val_batch1_pred.jpg",
        "val_batch0_labels.jpg",
        "val_batch1_labels.jpg",
    ]
    images = []
    for file in image_files:
        img_path = os.path.join(result_dir, file)
        if os.path.exists(img_path):
            images.append((file, img_path))

    if images:
        cols = st.columns(4)
        for i, (name, path) in enumerate(images):
            with open(path, "rb") as f:
                img = f.read()
            cols[i % 4].image(img, caption=name, use_container_width=True)
    else:
        st.info(
            "ğŸ“ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. runs/detect/{project_name}/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )


if st.button("ğŸš€ í•™ìŠµ ì‹œì‘"):
    current_training = {
        "model_arch": model_arch,
        "epochs": epochs,
        "batch": batch,
        "imgsz": imgsz,
        "optimizer": optimizer,
        "learning_rate": learning_rate,
        "project_name": project_name,
    }
    save_config("training", current_training)

    start_time = datetime.now()

    # data.yamlì˜ ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³´ì •
    import yaml

    yaml_path = os.path.abspath("dataset/data.yaml")
    if os.path.exists(yaml_path):
        with open(yaml_path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        for key in ["train", "val"]:
            if key in data:
                data[key] = os.path.abspath(data[key]).replace("\\", "/")
        with open(yaml_path, "w", encoding="utf-8") as f:
            yaml.dump(data, f, allow_unicode=True)

    data_yaml = yaml_path
    yolo_cmd = (
        f"yolo task=detect mode=train model={model_arch} data={data_yaml} "
        f"epochs={epochs} batch={batch} imgsz={imgsz} lr0={learning_rate} "
        f"optimizer={optimizer.lower()} name={project_name}"
    )
    st.info(f"ğŸ“¡ í•™ìŠµ ëª…ë ¹ ì‹¤í–‰ ì¤‘: {yolo_cmd}")

    with st.spinner("YOLO í•™ìŠµ ì§„í–‰ ì¤‘..."):
        result = run_training(yolo_cmd)

    end_time = datetime.now()

    if result.returncode == 0:
        st.success("ğŸ‰ í•™ìŠµ ì„±ê³µ")
        log_training(start_time, end_time, current_training, "success")

        # ìµœì¢… ëª¨ë¸ ê²½ë¡œë¥¼ config.yamlì— ì €ì¥
        best_model_path = os.path.join(result_dir, "weights", "best.pt")
        if os.path.exists(best_model_path):
            save_config("detection", {"model_path": best_model_path})
            st.info(
                f"âœ… ìµœì¢… ëª¨ë¸ ê²½ë¡œê°€ config.yamlì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {best_model_path}"
            )

        # âœ… í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì¶”ê°€
        st.subheader("ğŸ–¼ï¸ ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”")
        image_files = [
            "F1_curve.png",
            "P_curve.png",
            "R_curve.png",
            "PR_curve.png",
            "confusion_matrix.png",
            "confusion_matrix_normalized.png",
            "labels.jpg",
            "labels_correlogram.jpg",
            "val_batch0_pred.jpg",
            "val_batch1_pred.jpg",
            "val_batch0_labels.jpg",
            "val_batch1_labels.jpg",
        ]
        images = []
        for file in image_files:
            img_path = os.path.join(result_dir, file)
            if os.path.exists(img_path):
                images.append((file, img_path))

        if images:
            cols = st.columns(4)
            for i, (name, path) in enumerate(images):
                with open(path, "rb") as f:
                    img = f.read()
                cols[i % 4].image(img, caption=name, use_column_width=True)
        else:
            st.info(
                "ğŸ“ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. runs/detect/{project_name}/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”."
            )
        st.subheader("ğŸ“Š í•™ìŠµ ê²°ê³¼ ìš”ì•½")
        result_dir = os.path.join("runs", "detect", project_name)
        csv_path = os.path.join(result_dir, "results.csv")
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            st.line_chart(
                df[["metrics/precision(B)", "metrics/recall(B)", "metrics/mAP50(B)"]]
            )
        else:
            st.warning("results.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if os.path.exists(best_model_path):
            with open(best_model_path, "rb") as f:
                st.download_button("ğŸ“¥ Best ëª¨ë¸ ë‹¤ìš´ë¡œë“œ", f, file_name="best.pt")
    else:
        st.error("âŒ í•™ìŠµ ì‹¤íŒ¨")
        st.code(result.stdout)
